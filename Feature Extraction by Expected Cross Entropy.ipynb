{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "#nltk\n",
    "import nltk\n",
    "#stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#tokenizing\n",
    "from nltk import word_tokenize,sent_tokenize\n",
    "#Beautiful Soup\n",
    "from bs4 import BeautifulSoup \n",
    "# regex\n",
    "import re\n",
    "#word2vec\n",
    "from gensim.models import Word2Vec\n",
    "#machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读入评论文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('employee_reviews.csv')\n",
    "reviews = data[['company', 'pros', 'cons']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评论文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(review):\n",
    "    #Removing html tags\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #Retaining only alphabets.\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)   \n",
    "    #Converting to lower case and splitting\n",
    "    word_tokens= review_text.lower().split()\n",
    "    #Remove stopwords\n",
    "    stop_words= set(stopwords.words(\"english\"))     \n",
    "    word_tokens= [w for w in word_tokens if not w in stop_words]\n",
    "    #from words back to reviews\n",
    "    cleaned_review=\" \".join(word_tokens)\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean reviews\n",
    "reviews['pros']=reviews['pros'].apply(clean_reviews)\n",
    "reviews['cons']=reviews['cons'].apply(clean_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 期望交叉熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到类的字典\n",
    "def get_class_dict(doc_class_list):\n",
    "    class_set = sorted(list(set(doc_class_list)))\n",
    "    class_dict = dict(zip(class_set, range(len(class_set))))#class set 排序后，按照索引做出字典\n",
    "    return  class_dict\n",
    "\n",
    "#得到词的字典\n",
    "def get_term_dict(doc_terms_list):\n",
    "    term_set_dict = {}\n",
    "    for doc_terms in doc_terms_list:\n",
    "        for term in doc_terms:\n",
    "            term_set_dict[term] = 1\n",
    "    term_set_list = sorted(term_set_dict.keys())       \n",
    "    term_set_dict = dict(zip(term_set_list, range(len(term_set_list))))#term set 排序后，按照索引做出字典\n",
    "    return term_set_dict\n",
    "\n",
    "def stats_class_df(doc_class_list, class_dict):\n",
    "    class_df_list = [0] * len(class_dict)\n",
    "    for doc_class in doc_class_list:\n",
    "        class_df_list[class_dict[doc_class]] += 1\n",
    "    return class_df_list\n",
    "\n",
    "def stats_term_class_df(doc_terms_list, doc_class_list, term_dict, class_dict):\n",
    "    term_class_df_mat = np.zeros((len(term_dict), len(class_dict)), np.float32)\n",
    "    for k in range(len(doc_class_list)):\n",
    "        class_index = class_dict[doc_class_list[k]]\n",
    "        doc_terms = doc_terms_list[k]\n",
    "        for term in set(doc_terms):\n",
    "            term_index = term_dict[term]\n",
    "            term_class_df_mat[term_index][class_index] +=1\n",
    "    return  term_class_df_mat\n",
    "\n",
    "#期望交叉熵\n",
    "def calculateKL(class_df_list, term_set, term_class_df_mat, class_index):\n",
    "    A = term_class_df_mat#每个数代表一个特征出现属于某类别的文档数\n",
    "    B = np.array([(sum(x) - x).tolist() for x in A])\n",
    "    N = sum(class_df_list)#总文档数（总评论数）\n",
    "    term_df_array = np.sum(A, axis = 1)#所有词出现过的文档数的矩阵\n",
    "    class_df_array = np.sum(A, axis = 0)\n",
    "    class_set_size = len(class_df_list)#class的数量\n",
    "    sorted_term_score_index = []\n",
    "\n",
    "    p_t = term_df_array / N #Pt\n",
    "    p_c_t_mat =  (A + 1) / (A + B + class_set_size)\n",
    "    p_c_mat = np.array(class_df_list)/sum(class_df_list)\n",
    "    ece = p_t * np.sum(p_c_t_mat * np.log(p_c_t_mat/ p_c_mat), axis = 1)\n",
    "    cd = np.array([(x/sum(x)).tolist() for x in A])\n",
    "    dd = A/np.sum(A, axis = 0)\n",
    "    #cd_ece = [cd[:,i]*dd[:,i]*ece for i in range(len(class_df_list))]\n",
    "    i = class_index\n",
    "    cd_ece = cd[:,i]*dd[:,i]*ece\n",
    "    sorted_term_score_index = cd_ece.argsort()[: : -1]\n",
    "    term_set_fs = [term_set[index] for index in sorted_term_score_index]   \n",
    "    return term_set_fs\n",
    "\n",
    "def feature_selection(doc_str_list, doc_class_list, company):\n",
    "    vectorizer = CountVectorizer(binary = True)   \n",
    "    word_tokenizer = vectorizer.build_tokenizer()\n",
    "    doc_terms_list = [word_tokenizer(doc_str) for doc_str in doc_str_list]\n",
    "    \n",
    "    class_dict = get_class_dict(doc_class_list)\n",
    "    class_index = class_dict[company]\n",
    "    term_dict = get_term_dict(doc_terms_list)\n",
    "    class_df_list = stats_class_df(doc_class_list, class_dict)#每种类别的数量dict\n",
    "    class_count = class_df_list[class_index]\n",
    "    #print(\"the index and count:\", class_index, class_count)\n",
    "    term_class_df_mat = stats_term_class_df(doc_terms_list, doc_class_list, term_dict, class_dict)\n",
    "    term_set = [term[0] for term in sorted(term_dict.items(), key = lambda x : x[1])]\n",
    "    term_set_fs = []\n",
    "    term_set_fs = calculateKL(class_df_list, term_set, term_class_df_mat, class_index)\n",
    "    \n",
    "    return term_set_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取各类特征词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "company = 'google'#指定某一类\n",
    "doc_str_list= reviews['cons']\n",
    "doc_class_list = reviews['company']\n",
    "term_fs = feature_selection(doc_str_list, doc_class_list, company)\n",
    "term_set_fs = term_fs[:20]#取前20个特征词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google',\n",
       " 'big',\n",
       " 'company',\n",
       " 'work',\n",
       " 'large',\n",
       " 'projects',\n",
       " 'politics',\n",
       " 'mountain',\n",
       " 'bureaucracy',\n",
       " 'hours',\n",
       " 'many',\n",
       " 'impact',\n",
       " 'slow',\n",
       " 'long',\n",
       " 'view',\n",
       " 'cons',\n",
       " 'life',\n",
       " 'people',\n",
       " 'political',\n",
       " 'time']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_set_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
